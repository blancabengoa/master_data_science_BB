{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARATIVA MODELOS ESTUDIADOS\n",
    "\n",
    "En este notebook se presentan las métricas de accuracy, precision y recall que se han obtenido en los entrenamientos de los distintos modelos en cada fase de selección del modelo óptimo a nuestro problema. \n",
    "\n",
    "Descripción breve de cada fase:\n",
    "\n",
    "* MODELO 1: 3 años hidráulicos. Todas las feautures iniciales.\n",
    "\n",
    "* MODELO 2: 3 años hidráulicos. Eliminación de ACOPLADO_FR del dataset.\n",
    "\n",
    "* MODELO 3: 2 años hidráulicos. Eliminación de ACOPLADO_FR del dataset.\n",
    "\n",
    "* MODELO 4: (Fase XGBoost_FSelect) 2 años hidráulicos. Eliminación de ACOPLADO_FR, RESERVA_D-1, MES del data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerías necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Librerías para modelos\n",
    "\n",
    "#k-neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "#Arbol de decision\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Para agrupar clasificadores\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos1=[]\n",
    "\n",
    "names1= ['clfk_1','clfsvc_1','clfd_1','clfr_1','clfxb_1','clfb_1']\n",
    "path1='/Users/blancabengoa/Desktop/KSchool/TFM/Modelo1/'\n",
    "\n",
    "for k,n in enumerate(names1):\n",
    "    modelos1.append(pickle.load(open(path1 + str(n) +\".pkl\",\"rb\")))\n",
    "\n",
    "X_test1=pickle.load(open(path1 + \"X_test.pkl\",\"rb\"))\n",
    "y_test1=pickle.load(open(path1 + \"y_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5261, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos2=[]\n",
    "\n",
    "names2= ['clfk_2','clfsvc_2','clfd_2','clfr_2','clfxb_2','clfb_2']\n",
    "path2='/Users/blancabengoa/Desktop/KSchool/TFM/Modelo2/'\n",
    "\n",
    "for k,n in enumerate(names2):\n",
    "    modelos2.append(pickle.load(open(path2 + str(n) +\".pkl\",\"rb\")))\n",
    "\n",
    "X_test2=pickle.load(open(path2 + \"X_test.pkl\",\"rb\"))\n",
    "y_test2=pickle.load(open(path2 + \"y_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5261, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos3=[]\n",
    "\n",
    "names3= ['clfk_3','clfsvc_3','clfd_3','clfr_3','clfxb_3','clfb_3']\n",
    "path3='/Users/blancabengoa/Desktop/KSchool/TFM/Modelo3/'\n",
    "\n",
    "for k,n in enumerate(names3):\n",
    "    modelos3.append(pickle.load(open(path3 + str(n) +\".pkl\",\"rb\")))\n",
    "\n",
    "X_test3=pickle.load(open(path3 + \"X_test.pkl\",\"rb\"))\n",
    "y_test3=pickle.load(open(path3 + \"y_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo4**\n",
    "\n",
    "(Solo XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4='/Users/blancabengoa/Desktop/KSchool/TFM/Modelo4/'\n",
    "\n",
    "modelo4=pickle.load(open(path4 + \"clfxb_4.pkl\",\"rb\"))\n",
    "X_test4=pickle.load(open(path4 + \"X_test.pkl\",\"rb\"))\n",
    "y_test4=pickle.load(open(path4 + \"y_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo KNeighborsClassifier\n",
      "\n",
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.55      0.57      2258\n",
      "          1       0.68      0.72      0.70      3003\n",
      "\n",
      "avg / total       0.64      0.65      0.64      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.55      0.57      2258\n",
      "          1       0.68      0.72      0.70      3003\n",
      "\n",
      "avg / total       0.64      0.65      0.64      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.58      0.59      1518\n",
      "          1       0.69      0.71      0.70      1986\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3504\n",
      "\n",
      "\n",
      "Modelo SVC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      2258\n",
      "          1       0.57      1.00      0.73      3003\n",
      "\n",
      "avg / total       0.33      0.57      0.41      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      2258\n",
      "          1       0.57      1.00      0.73      3003\n",
      "\n",
      "avg / total       0.33      0.57      0.41      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1518\n",
      "          1       0.57      1.00      0.72      1986\n",
      "\n",
      "avg / total       0.32      0.57      0.41      3504\n",
      "\n",
      "\n",
      "Modelo DecisionTreeClassifier\n",
      "\n",
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.23      0.33      2258\n",
      "          1       0.61      0.89      0.72      3003\n",
      "\n",
      "avg / total       0.61      0.61      0.56      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.23      0.33      2258\n",
      "          1       0.61      0.89      0.72      3003\n",
      "\n",
      "avg / total       0.61      0.61      0.56      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.29      0.40      1518\n",
      "          1       0.62      0.89      0.73      1986\n",
      "\n",
      "avg / total       0.64      0.63      0.59      3504\n",
      "\n",
      "\n",
      "Modelo RandomForestClassifier\n",
      "\n",
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.02      0.04      2258\n",
      "          1       0.58      1.00      0.73      3003\n",
      "\n",
      "avg / total       0.69      0.58      0.43      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.02      0.04      2258\n",
      "          1       0.58      1.00      0.73      3003\n",
      "\n",
      "avg / total       0.67      0.58      0.43      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.02      0.04      1518\n",
      "          1       0.57      1.00      0.73      1986\n",
      "\n",
      "avg / total       0.66      0.57      0.43      3504\n",
      "\n",
      "\n",
      "Modelo XGBClassifier\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.50      0.59      2258\n",
      "          1       0.69      0.84      0.76      3003\n",
      "\n",
      "avg / total       0.70      0.70      0.69      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.51      0.59      2258\n",
      "          1       0.70      0.84      0.76      3003\n",
      "\n",
      "avg / total       0.70      0.70      0.69      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.55      0.62      1518\n",
      "          1       0.71      0.82      0.76      1986\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3504\n",
      "\n",
      "\n",
      "SELECCIONADO:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.54      0.61      1518\n",
      "          1       0.70      0.83      0.76      1986\n",
      "\n",
      "avg / total       0.70      0.70      0.69      3504\n",
      "\n",
      "\n",
      "Modelo BaggingClassifier\n",
      "\n",
      "Caso 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.55      0.58      2258\n",
      "          1       0.68      0.73      0.71      3003\n",
      "\n",
      "avg / total       0.65      0.65      0.65      5261\n",
      "\n",
      " Caso 2:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.55      0.58      2258\n",
      "          1       0.68      0.73      0.71      3003\n",
      "\n",
      "avg / total       0.65      0.65      0.65      5261\n",
      "\n",
      " Caso 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.58      0.59      1518\n",
      "          1       0.69      0.71      0.70      1986\n",
      "\n",
      "avg / total       0.65      0.65      0.65      3504\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(modelos1):\n",
    "    print('Modelo ' + list(str(m).split(\"(\"))[0] + '\\n')\n",
    "    print('Caso 1:\\n' + classification_report(y_test1,modelos1[k].predict(X_test1)) + '\\n', \n",
    "          'Caso 2:\\n' + classification_report(y_test2,modelos2[k].predict(X_test2)) + '\\n', \n",
    "          'Caso 3:\\n' + classification_report(y_test3,modelos3[k].predict(X_test3))+ '\\n')\n",
    "    if k==4:\n",
    "        print('SELECCIONADO:\\n' + classification_report(y_test4,modelo4.predict(X_test4))+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: \n",
      "KNeighborsClassifier\n",
      "0.68, 0.68, 0.69\n",
      "\n",
      "Precision: \n",
      "SVC\n",
      "0.57, 0.57, 0.57\n",
      "\n",
      "Precision: \n",
      "DecisionTreeClassifier\n",
      "0.61, 0.61, 0.62\n",
      "\n",
      "Precision: \n",
      "RandomForestClassifier\n",
      "0.58, 0.58, 0.57\n",
      "\n",
      "Precision: \n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69, 0.70, 0.71\n",
      "\n",
      "Precision: \n",
      "BaggingClassifier\n",
      "0.68, 0.68, 0.69\n",
      "\n",
      "SELECCIONADO: 0.70/n\n",
      "Accuracy: \n",
      "KNeighborsClassifier\n",
      "0.65, 0.65, 0.65\n",
      "\n",
      "Accuracy: \n",
      "SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57, 0.57, 0.57\n",
      "\n",
      "Accuracy: \n",
      "DecisionTreeClassifier\n",
      "0.61, 0.61, 0.63\n",
      "\n",
      "Accuracy: \n",
      "RandomForestClassifier\n",
      "0.58, 0.58, 0.57\n",
      "\n",
      "Accuracy: \n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70, 0.70, 0.70\n",
      "\n",
      "Accuracy: \n",
      "BaggingClassifier\n",
      "0.65, 0.65, 0.65\n",
      "\n",
      "SELECCIONADO: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(modelos1):\n",
    "    print('Precision: \\n' + list(str(m).split(\"(\"))[0])\n",
    "    print('%.2f' %precision_score(y_test1,modelos1[k].predict(X_test1)) + ', %.2f' %precision_score(y_test2,modelos2[k].predict(X_test2))  +\n",
    "          ', %.2f' %precision_score(y_test3,modelos3[k].predict(X_test3)) + '\\n')\n",
    "print('SELECCIONADO: %.2f' %precision_score(y_test4,modelo4.predict(X_test4)) + '/n')\n",
    "\n",
    "for k,m in enumerate(modelos1):\n",
    "    print('Accuracy: \\n' + list(str(m).split(\"(\"))[0])\n",
    "    print('%.2f' %accuracy_score(y_test1,modelos1[k].predict(X_test1)) + ', %.2f' %accuracy_score(y_test2,modelos2[k].predict(X_test2)) + \n",
    "          ', %.2f' %accuracy_score(y_test3,modelos3[k].predict(X_test3))+'\\n')\n",
    "print('SELECCIONADO: %.2f' %accuracy_score(y_test4,modelo4.predict(X_test4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
